{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate SP3 Input Parameters \n",
    "This file is used for generating SP3 input files using data from dyanamic analysis to perform FEMA P-58 loss assessment on SP3. \n",
    "Jointly lognormal distributions are assumed for all engineering demand parameters (EDPs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import random\n",
    "\n",
    "from scipy.stats import lognorm\n",
    "from scipy.stats import binom\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import truncnorm\n",
    "from scipy.stats import uniform\n",
    "from scipy.optimize import minimize\n",
    "from scipy import interpolate\n",
    "\n",
    "from Component import component # Predefined component class\n",
    "import random\n",
    "np.random.seed(1000)\n",
    "\n",
    "def SampleEDP(aggregatedEDP, beta, NumRealizations):\n",
    "    # This function is used for randomly sampling engineering demand parameters used for loss assessment\n",
    "    ##############################################################################################################################################\n",
    "    # Input:\n",
    "    # aggregatedEDP      Aggregated EDPs at one intensity level, including SDR, PFA and RDR, attention: this function takes the original EDPs from the analsis\n",
    "    # beta               Uncertainties, first row is model uncertainty, second row is ground motion uncertainty         \n",
    "    # NumRealizations    Number of simulations at current intensity level\n",
    "    # Output:\n",
    "    # W                  Random sampled EDPs, including both collapse and non-collapse EDPs\n",
    "    ##############################################################################################################################################\n",
    "     \n",
    "    EDPs = aggregatedEDP\n",
    "    # ln scale of the input EDP\n",
    "    lnEDPs = np.log(EDPs)\n",
    "\n",
    "    # Number of rows\n",
    "    num_rec = EDPs.shape[0]\n",
    "    # Number of columns \n",
    "    num_var = EDPs.shape[1]\n",
    "\n",
    "    lnEDPs_mean = np.array(np.mean(lnEDPs, axis = 0).T)\n",
    "    lnEDPs_cov = np.cov(lnEDPs.T)\n",
    "\n",
    "    lnEDPs_cov_rank = np.linalg.matrix_rank(lnEDPs_cov)\n",
    "\n",
    "    # pay attention to the data format here, it has to be a column vector\n",
    "    sigma = np.array(np.sqrt(np.diag(lnEDPs_cov))).reshape([num_var,1]) \n",
    "    sigmap2 = sigma * sigma\n",
    "\n",
    "    R = lnEDPs_cov / (np.matmul(sigma,sigma.T))\n",
    "\n",
    "    B = np.array(beta).reshape([1,2])\n",
    "\n",
    "    # Incorporate with uncertainties\n",
    "    sigmap2 = sigmap2 + B[:,0] * B[:,0]\n",
    "    sigmap2 = sigmap2 + B[:,1] * B[:,1]\n",
    "    sigma = np.sqrt(sigmap2)\n",
    "    sigma2 = np.matmul(sigma , sigma.T) \n",
    "    lnEDPs_cov_inflated = R * sigma2\n",
    "\n",
    "\n",
    "    D2_total,L_total = np.linalg.eig(lnEDPs_cov_inflated)\n",
    "\n",
    "    idx = D2_total.argsort()  \n",
    "    D2_total = D2_total[idx]\n",
    "    L_total = L_total[:,idx]\n",
    "\n",
    "\n",
    "    if lnEDPs_cov_rank >= num_var:\n",
    "        L_use = L_total\n",
    "    else:\n",
    "        L_use = L_total[:, num_var - lnEDPs_covrank + 1 : num_var] # still have to check this part\n",
    "\n",
    "    if lnEDPs_cov_rank >= num_var:\n",
    "        D2_use = D2_total\n",
    "    else: D2_use = D2_total[num_var - lnEDPs-cov_rank + 1: num_var] # still have to check this part\n",
    "\n",
    "    D_use =np.diagflat(np.sqrt(D2_use))\n",
    "\n",
    "    if lnEDPs_cov_rank >= num_var:\n",
    "        U = np.random.randn(NumRealizations*num_var).reshape([num_var, NumRealizations])\n",
    "    else: U = np.random.randn(NumRealizations, lnEDPs_cov_rank).reshape([num_var, NumRealizations])\n",
    "\n",
    "    Lambda = -np.matmul(L_use , D_use)\n",
    "\n",
    "    Z = np.matmul(Lambda , U) + np.repeat(lnEDPs_mean.reshape([num_var,1]), NumRealizations, axis=1)\n",
    "\n",
    "    lnEDPs_sim_mean = np.mean(Z.T, axis = 0)\n",
    "    lnEDPs_sim_cov = np.cov(Z)\n",
    "\n",
    "    A = lnEDPs_sim_mean/lnEDPs_mean.T  #Table G-7, or Table G-16\n",
    "    B = lnEDPs_sim_cov/lnEDPs_cov  #Table G-8, or Table G-17\n",
    "    W = np.exp(Z)\n",
    "    sampledEDP = pd.DataFrame(W.T,columns = aggregatedEDP.columns)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (r'C:\\Users\\User\\Desktop\\PEER CEA Models\\Baseline\\ModelAssembling\\BuildingName.txt') as f:\n",
    "    BuildingName = f.read()\n",
    "f.close()\n",
    "\n",
    "BuildingName = BuildingName.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over all input folders \n",
    "BaseDirectory = r'C:\\Users\\User\\Desktop\\PEER CEA Models\\Baseline\\Results'\n",
    "NumHazardLevel = 16\n",
    "\n",
    "for p in range(len(BuildingName)):\n",
    "    os.chdir(BaseDirectory + '/%s'%BuildingName[p])\n",
    "    SDRTotal = pd.read_csv('SDR.csv', index_col = 0)\n",
    "    SDRTotal.columns = SDRTotal.columns.map(int)\n",
    "    PFATotal = pd.read_csv('PFA.csv', index_col = 0)\n",
    "    PFATotal.columns = PFATotal.columns.map(int)\n",
    "    RDRTotal = pd.read_csv('RDR.csv', index_col = 0)\n",
    "    RDRTotal.columns = RDRTotal.columns.map(int)\n",
    "\n",
    "    NumStory = SDRTotal.shape[1]-3\n",
    "    \n",
    "    SDR_SP3 = pd.DataFrame(columns=SDRTotal.columns)\n",
    "    SDR_SP3[0] = SDRTotal[0]\n",
    "    SDR_SP3[1] = SDRTotal[1]\n",
    "    SDR_SP3[2] = SDRTotal[2]\n",
    "   \n",
    "    PFA_SP3 = pd.DataFrame(columns=PFATotal.columns)\n",
    "    PFA_SP3[0] = PFATotal[0]\n",
    "    PFA_SP3[1] = PFATotal[1]\n",
    "    PFA_SP3[2] = PFATotal[2]\n",
    "    \n",
    "    RDR_SP3 = pd.DataFrame(columns=RDRTotal.columns)\n",
    "    RDR_SP3[0] = RDRTotal[0]\n",
    "    RDR_SP3[1] = RDRTotal[1]\n",
    "    RDR_SP3[2] = RDRTotal[2]\n",
    "    \n",
    "    tempSDR = np.empty([0,NumStory])\n",
    "    tempPFA = np.empty([0,NumStory+1])\n",
    "    tempRDR = np.empty([0])\n",
    "    \n",
    "    for i in range(1,17):\n",
    "        SDRX = SDRTotal[(SDRTotal.loc[:,0] == i) & (SDRTotal.loc[:,1] == 1)]\n",
    "        PFAX = PFATotal[(PFATotal.loc[:,0] == i) & (PFATotal.loc[:,1] == 1)]\n",
    "        RDRX = RDRTotal[(RDRTotal.loc[:,0] == i) & (RDRTotal.loc[:,1] == 1)]\n",
    "\n",
    "        SDRZ = SDRTotal[(SDRTotal.loc[:,0] == i) & (SDRTotal.loc[:,1] == 2)]\n",
    "        PFAZ = PFATotal[(PFATotal.loc[:,0] == i) & (PFATotal.loc[:,1] == 2)]\n",
    "        RDRZ = RDRTotal[(RDRTotal.loc[:,0] == i) & (RDRTotal.loc[:,1] == 2)]\n",
    "        \n",
    "        # Prepare the EDPs at current intensity level and sample EDPs\n",
    "        SDRX_pure = SDRX.loc[:,3:SDRX.shape[1]]\n",
    "        PFAX_pure = PFAX.loc[:,3:PFAX.shape[1]]\n",
    "        RDRX_pure = RDRX.loc[:,3:RDRX.shape[1]]\n",
    "\n",
    "        AggregatedXEDPs = pd.concat([SDRX_pure, PFAX_pure, RDRX_pure], axis=1)\n",
    "\n",
    "        SDRZ_pure = SDRZ.loc[:,3:SDRZ.shape[1]]\n",
    "        PFAZ_pure = PFAZ.loc[:,3:PFAZ.shape[1]]\n",
    "        RDRZ_pure = RDRZ.loc[:,3:RDRZ.shape[1]]\n",
    "\n",
    "        AggregatedZEDPs = pd.concat([SDRZ_pure, PFAZ_pure, RDRZ_pure], axis=1)\n",
    "\n",
    "        temp = pd.concat([AggregatedXEDPs,AggregatedZEDPs], axis = 0, ignore_index=True)\n",
    "        AggregatedEDP = pd.DataFrame(data = temp.values.reshape([AggregatedXEDPs.shape[0],AggregatedXEDPs.shape[1]*2]))\n",
    "        \n",
    "        SampledEDP = SampleEDP(AggregatedEDP, np.array([0,0]), 10000)\n",
    "        sampledEDPXs = SampledEDP[0:int(SampledEDP.shape[0]/2)]\n",
    "        Cur_SDRX = sampledEDPXs[0:NumStory]\n",
    "        Cur_PFAX = sampledEDPXs[NumStory:NumStory+NumStory+1]\n",
    "        Cur_RDRX = sampledEDPXs[-1]\n",
    "\n",
    "        sampledEDPZs = SampledEDP[int(SampledEDP.shape[0]/2):SampledEDP.shape[0]]\n",
    "        Cur_SDRZ = sampledEDPZs[0:NumStory]\n",
    "        Cur_PFAZ = sampledEDPZs[NumStory:NumStory+NumStory+1]\n",
    "        Cur_RDRZ = sampledEDPZs[-1]\n",
    "        \n",
    "        MaxSDR = np.maximum(np.max(Cur_SDRX, axis = 0),np.max(Cur_SDRZ, axis = 0))   \n",
    "        \n",
    "        tempSDR = np.concatenate((tempSDR,np.transpose(Cur_SDRX[:,MaxSDR<0.2][:,0:45])))\n",
    "        tempSDR = np.concatenate((tempSDR,np.transpose(Cur_SDRZ[:,MaxSDR<0.2][:,0:45])))\n",
    "\n",
    "        tempPFA = np.concatenate((tempPFA,np.transpose(Cur_PFAX[:,MaxSDR<0.2][:,0:45])))\n",
    "        tempPFA = np.concatenate((tempPFA,np.transpose(Cur_PFAZ[:,MaxSDR<0.2][:,0:45])))\n",
    "        \n",
    "        tempRDR = np.concatenate((tempRDR,np.transpose(Cur_RDRX[MaxSDR<0.2][0:45])))\n",
    "        tempRDR = np.concatenate((tempRDR,np.transpose(Cur_RDRZ[MaxSDR<0.2][0:45])))\n",
    "        \n",
    "        \n",
    "    SDR_SP3.iloc[:,3:] = tempSDR\n",
    "    PFA_SP3.iloc[:,3:] = tempPFA\n",
    "    RDR_SP3.iloc[:,3:] = tempRDR\n",
    "\n",
    "    if not os.path.isdir(BaseDirectory + '/%s'%BuildingName[p] + '/SP3 Input'):\n",
    "        os.mkdir(BaseDirectory + '/%s'%BuildingName[p] + '/SP3 Input')\n",
    "    os.chdir(BaseDirectory + '/%s'%BuildingName[p] + '/SP3 Input')\n",
    "    \n",
    "    SDR_SP3.to_csv('SDR.csv', header = None, index = False)\n",
    "    PFA_SP3.to_csv('PFA.csv', header = None, index = False)\n",
    "    RDR_SP3.to_csv('RDR.csv', header = None, index = False)\n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1350, 2)"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "tempSDR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjust Median Collapse Intensity per FEMA P-695"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSF = np.array([1.09571922, 1.01245261, 1.0930497 , 1.02471603, 1.10805072,\n",
    "       1.02748051, 1.09393267, 1.03427207, 1.08386949, 1.02451625,\n",
    "       1.08326639, 1.02455288, 1.1037251 , 1.02804048, 1.10156877,\n",
    "       1.03669735, 1.08191171, 1.02766901, 1.08276446, 1.03136322,\n",
    "       1.08701776, 1.02575623, 1.10124591, 1.02880187, 1.0833023 ,\n",
    "       1.03166676, 1.0822175 , 1.03089174, 1.10448858, 1.024396  ,\n",
    "       1.09811497, 1.02982435, 1.07952327, 1.02831036, 1.07723176,\n",
    "       1.03009791, 1.10871187, 1.02744448, 1.09841607, 1.0336288 ,\n",
    "       1.08562203, 1.02924885, 1.08320047, 1.03083144, 1.11670231,\n",
    "       1.02818649, 1.11299566, 1.03992404, 1.08208485, 1.02949064,\n",
    "       1.07724773, 1.02921092, 1.09171821, 1.02566203, 1.10887921,\n",
    "       1.0285508 , 1.08420665, 1.02948647, 1.0829342 , 1.02941277,\n",
    "       1.11828912, 1.0272267 , 1.11364835, 1.03257194, 1.08301218,\n",
    "       1.0278338 , 1.07516192, 1.02886966, 1.11339058, 1.02704789,\n",
    "       1.09757539, 1.03283428, 1.08393951, 1.02951265, 1.08316924,\n",
    "       1.02944363, 1.10942837, 1.02876181, 1.11313005, 1.03862263,\n",
    "       1.08240426, 1.0290608 , 1.07479885, 1.02921412, 1.08913195,\n",
    "       1.02566268, 1.09014529, 1.02823359, 1.08331827, 1.028954  ,\n",
    "       1.08276071, 1.02900985, 1.11722086, 1.02715933, 1.11235383,\n",
    "       1.03294298])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "BaseDirectory = '/Users/rover/Desktop/Cost_Benefit/20190701UpdateDesignForSeismicParameters/Updated Building Performance'\n",
    "NumHazardLevel = 15\n",
    "\n",
    "for p in range(1,97):\n",
    "    os.chdir(BaseDirectory + '/case%i'%p)\n",
    "    CollapseMedian = pd.read_csv('CollapseFragility.csv',header = None)\n",
    "    CollapseMedian.iloc[0,0] *= SSF[p-1]\n",
    "    \n",
    "    os.chdir('/Users/rover/Desktop/Cost_Benefit/20190701UpdateDesignForSeismicParameters/SP3 Input/%s'%BuildingName[p-1])\n",
    "    \n",
    "    CollapseMedian.to_csv('CollapseFragility.csv',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.130442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.229811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  1.130442\n",
       "1  0.229811"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CollapseMedian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hazard Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "HazardLevel = np.array([0.162958971,0.325917943,0.488876914,0.651835885,0.814794857,\n",
    "                        0.977753828,1.140712799,1.303671771,1.466630742,1.629589713,\n",
    "                        1.792548685,1.955507656,2.118466627,2.281425599,2.44438457])\n",
    "\n",
    "Sa = np.array([0.0025,0.0045,0.0075,0.0113,0.0169,0.0253,0.038,0.057,0.0854,\n",
    "                   0.128,0.192,0.288,0.432,0.649,0.973,\n",
    "                   1.46,2.19,3.28,4.92,7.38])\n",
    "Lambda = np.array([1.2858232,1.0615758,0.84598525,0.6784487,0.53093991,0.40578048,0.303132,0.22138945,0.15660468,0.10588062,\n",
    "                   0.067680774,0.040523182,0.022339423,0.01099528,0.0047231629,0.0017479081,5.8443237E-4,1.9411083E-4,\n",
    "                   6.5659132E-5,2.0956643E-5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hazard_rate = np.interp(HazardLevel, Sa, Lambda)\n",
    "Return_period = 1/Hazard_rate\n",
    "Prop_exceedance = 1-np.exp(-Hazard_rate)\n",
    "Data = {'Sa':HazardLevel,\n",
    "       'Prop of exceedence':Prop_exceedance,\n",
    "       'Lambda':Hazard_rate,\n",
    "       'return period': Return_period}\n",
    "HazardInfo = pd.DataFrame(data = Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/rover/Desktop/Cost_Benefit/20190701UpdateDesignForSeismicParameters/SP3 Input')\n",
    "HazardInfo.to_csv('HazardCurve.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08501457, 0.03573505, 0.01936606, 0.01094038, 0.00778576,\n",
       "       0.00469412, 0.00369855, 0.00270297, 0.00173734, 0.00147762,\n",
       "       0.00121789, 0.00095817, 0.00069844, 0.00055169, 0.00049334])"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hazard_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}